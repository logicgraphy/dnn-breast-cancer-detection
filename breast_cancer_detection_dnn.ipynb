{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Detection\n",
    "#### (Data Source - University of Wisconsin Hospital, Madison)\n",
    "For this assignment, I have used TFlearn library built on top of Tensorflow. It provides higher-level API to Tensorflow in order to speedup experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed random state initialization for consistent outcomes. \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from file\n",
    "data = np.genfromtxt(\"breast_cancer.data\", delimiter=\",\", missing_values=\"?\", filling_values=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "The data available for this experimentation has 10 plus the class attribute. Attributes 2 through 10 will be used to represent instances. Each instance has one of 2 possible classes: benign or malignant.\n",
    "\n",
    "class 2 = benign\n",
    "\n",
    "class 4 = malignant\n",
    "\n",
    "First, we will split the attributes into inputs (X) and outputs(Y). \n",
    "\n",
    "Also, we will convert Y into a binary matrix form for the ease of calculations.\n",
    "\n",
    "Therefore, expected tranformation will be as follows:\n",
    "\n",
    "2 = [1 0]\n",
    "\n",
    "4 = [0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the X\n",
    "dataX = data[:, 1:-1]\n",
    "\n",
    "#Separate the Y\n",
    "pre_dataY = data[:, -1]\n",
    "\n",
    "#Convert the Y to binary form\n",
    "dataY = np.zeros((pre_dataY.size, 2))\n",
    "\n",
    "for i in range(len(pre_dataY)):\n",
    "    if pre_dataY[i] == 2:\n",
    "        dataY[i][0] = 1\n",
    "    else:\n",
    "        dataY[i][1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its a good practice to randomize the order of data to eliminate any biases while training the model.  Make sure to use same permutation for both X and Y to maintain data accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mix up the data\n",
    "permutation = np.random.permutation(dataX.shape[0])\n",
    "dataX = dataX[permutation]\n",
    "dataY = dataY[permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 attributes (2 through 10) that will be input to the network; therefore, input layer will consist of 9 nodes.\n",
    "\n",
    "The expected output is in binary form; therefore, output layer will consist of 2 nodes.\n",
    "\n",
    "Setting up hyperparameters is more of art than science; therefore, we will keep tunning them until the desired accuracy is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set network variables and hyperparameters\n",
    "nInput = 9\n",
    "nHidden = 25\n",
    "nOutput = 2\n",
    "alpha = 0.01\n",
    "nEpochs = 100\n",
    "testSplit = 0.15\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up layers and network\n",
    "input_layer: creates a placeholder for data input with 9 nodes\n",
    "\n",
    "hidden_layer: creates a layer of 25 nodes where each node from input_layer is connected to each node in hidden layer. The activation function `sigmoid` is a pre-defined function and it takes care of biases and wieghts. \n",
    "\n",
    "output_layer: creates output layer with 2 nodes and both nodes are fully connected with each node from hidden layer. It uses pre-defined `softmax` function for the final output.\n",
    "\n",
    "network: Tflearn makes it easy to create regression by taking care of calculating cost/loss, backpropogation and optimization. It uses pre-defined optimizer and loss functions. \n",
    "\n",
    "model: Let Tflearn create a deep neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/randeepsingh/venv/lib/python2.7/site-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "input_layer = tflearn.input_data(shape=[None, nInput])\n",
    "hidden_layer = tflearn.fully_connected(input_layer, nHidden, activation=\"sigmoid\")\n",
    "output_layer = tflearn.fully_connected(hidden_layer, nOutput, activation=\"softmax\")\n",
    "\n",
    "network = tflearn.regression(output_layer, optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "                               learning_rate=alpha, batch_size=batchSize)\n",
    "\n",
    "model = tflearn.DNN(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of data points used for testing\n",
    "num_test = int(testSplit * len(data))\n",
    "\n",
    "#Split data into train and  test\n",
    "trainX = dataX[:-num_test]\n",
    "testX = dataX[-num_test:]\n",
    "\n",
    "trainY = dataY[:-num_test]\n",
    "testY = dataY[-num_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.10862\u001b[0m\u001b[0m | time: 0.023s\n",
      "| Adam | epoch: 100 | loss: 0.10862 - acc: 0.9637 -- iter: 576/595\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.10620\u001b[0m\u001b[0m | time: 0.026s\n",
      "| Adam | epoch: 100 | loss: 0.10620 - acc: 0.9642 -- iter: 595/595\n",
      "--\n",
      "('Final Accuracy:', [0.9807692170143127])\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, n_epoch=nEpochs, show_metric=True)\n",
    "\n",
    "print(\"Final Accuracy:\", model.evaluate(testX, testY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
